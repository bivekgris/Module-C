{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import xml.dom.minidom as xml\n",
    "import requests\n",
    "\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <mark style=\"background: #801010; color: #ffffff;\" >C</mark> Week 1: Working with Structured Data\n",
    "\n",
    "------\n",
    "\n",
    "### Instructions:\n",
    "\n",
    "- Complete 50 points worth of questions to pass the assessment\n",
    "- You can attempt any number of questions and in any order provided you pass at least 50 points.\n",
    "- These questions should be attempted directly in this notebook.\n",
    "- Be sure to check your work before submitting.\n",
    "- Do not remove any provided markings from the answer spaces.\n",
    "- Do not make any changes to this notebook outside of the answer spaces provided.\n",
    "  \n",
    "#### Submitting\n",
    "\n",
    "- Reset your outputs before submitting\n",
    "- Select the `Kernel` menu, then either `Restart & Run Clear Output` or `Restart & Run All`\n",
    "- Don't forget to save your notebook after this step\n",
    "- Submit your .ipynb file to Gradescope using Git & GitHub\n",
    "- You can submit as many times as needed\n",
    "- When reviewing results, ignore any results listed under \"Public Tests\"  \n",
    "  (There are no \"Public Tests\" in this assignment)\n",
    "\n",
    "For more information, see the assessment page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 01 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(5 Points)\n",
    "\n",
    "In the file `username.csv`, find the header row (the first line of the file) and assign the list of column names to the variable `header`.\n",
    "\n",
    "\n",
    "---\n",
    "<details>\n",
    "  <summary><span style=\"color:blue\">Hints for viewing data</span></summary>\n",
    "   Jupyter Notebook provides a good facility to view some types of data such as CSV. It can be a better alternative to Microsoft Excel or Google Sheets to provide a lightweight overview of data and allows a delimiter to be set when opening files.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your solution here\n",
    "df = open('username.csv','r')\n",
    "reader = csv.reader(df)\n",
    "reader = list(reader)\n",
    "header = reader[0]\n",
    "print(header)\n",
    "df.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 02 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(5 Points)\n",
    "\n",
    "Open the file `username.csv` and remove the 'Identifier' column of data. Assign the remaining three columns to the variable `no_id_data` like:\n",
    "```python\n",
    "[['Username', 'First name', 'Last name'],\n",
    " ['booker12', 'Rachel', 'Booker'],\n",
    " ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your solution here\n",
    "import csv\n",
    "with open('username.csv','r+') as df:\n",
    "    reader = csv.reader(df)\n",
    "    no_id_data = []\n",
    "    for row in reader:\n",
    "        no_id_data.append(row[1:])\n",
    "    print(no_id_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 03 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(5 Points)\n",
    "\n",
    "Open the file `email-password-recovery-code.csv` and remove all rows where the user is located in London. Save the result to the file `email-password-manchester-only.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your solution here\n",
    "with open('email-password-recovery-code.csv','r') as df:\n",
    "    reader = csv.reader(df)\n",
    "    reader = list(reader)\n",
    "    \n",
    "    new_lst = []\n",
    "    for i in range(len(reader)):\n",
    "        if 'London' in reader[i]:\n",
    "            pass\n",
    "        else:\n",
    "            new_lst.append(reader[i])\n",
    "    with open('email-password-manchester-only.csv','w') as new:\n",
    "        writer = csv.writer(new)\n",
    "        writer = list(new_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 04 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(5 Points)\n",
    "\n",
    "The file `weather.csv` has iso-8859-1 encoding. Open this file while ensuring the correct encoding is specified. Find the highest maximum temperature and the lowest minimum temperature and assign them to the tuple `extremes` like `(max, min)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your solution here\n",
    "#extremes = (40.3, 11.7)\n",
    "df = open('weather.csv','r', encoding='iso-8859-1')\n",
    "reader = csv.DictReader(df)\n",
    "temp = []\n",
    "for row in reader:\n",
    "    temp.append([row['MinTemp'],row['MaxTemp']])\n",
    "#print(temp)\n",
    "new_temp = []\n",
    "#extremes = ()\n",
    "for sublist in temp:\n",
    "    for temps in sublist:\n",
    "        new_temp.append(float(temps))\n",
    "extremes = (max(new_temp),min(new_temp))\n",
    "print(extremes)\n",
    "df.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 05 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(5 Points)\n",
    "\n",
    "Open the same file `weather.csv` and remove the header line (which contains the problematic character for the degree symbol encoded as iso-8859-1. Write the rest of the file data to a new file called `weather-utf-8.csv` with `utf-8` encoding.\n",
    "\n",
    "---\n",
    "<details>\n",
    "  <summary><span style=\"color:blue\">Opening two files at a time</span></summary>\n",
    "   One solution to the problem is to open two files in the same with-as context manager like:<br /><br />\n",
    "    <pre>\n",
    "    with open(\"in.csv\", \"r\") as infile, open(\"out.csv\", \"w\") as outfile:\n",
    "        reader = csv.reader(infile)\n",
    "        writer = csv.writer(outfile)\n",
    "    </pre>\n",
    "    Then as you iterate through the input file, you can simultaneously be writing to the output file.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your solution here\n",
    "with open('weather.csv','r',encoding='iso-8859-1') as infile, open('weater-utf-8.csv','w',encoding='utf-8') as outfile:\n",
    "    next(infile)\n",
    "    reader = csv.reader(infile)\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerows(reader)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Question 06 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(5 Points)\n",
    "\n",
    "Create your own CSV file `random-dice.csv` with five columns and a header as follows:\n",
    "```python\n",
    "   'Roll #', 'D1', 'D2', 'D3', '3D6'\n",
    "```\n",
    "The first column shall be a counter from 1 to 10. Column 1 through 3 will contain random numbers between 1 and 6 generated to simulate the rolling of three six sided dice. The final column will contain the sum of the three dice in the range 3 .. 18. There shall be 100 rows of dice data.\n",
    "\n",
    "Thus, the seventh row of data might look like:\n",
    "```python\n",
    "   7,3,3,4,10\n",
    "```    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Roll #': 1, 'D1': 6, 'D2': 6, 'D3': 1, '3D6': 13}, {'Roll #': 2, 'D1': 2, 'D2': 1, 'D3': 4, '3D6': 13}, {'Roll #': 3, 'D1': 1, 'D2': 6, 'D3': 4, '3D6': 13}, {'Roll #': 4, 'D1': 3, 'D2': 2, 'D3': 4, '3D6': 13}, {'Roll #': 5, 'D1': 5, 'D2': 3, 'D3': 2, '3D6': 13}, {'Roll #': 6, 'D1': 5, 'D2': 6, 'D3': 5, '3D6': 13}, {'Roll #': 7, 'D1': 3, 'D2': 2, 'D3': 4, '3D6': 13}, {'Roll #': 8, 'D1': 3, 'D2': 3, 'D3': 3, '3D6': 13}, {'Roll #': 9, 'D1': 4, 'D2': 5, 'D3': 4, '3D6': 13}, {'Roll #': 10, 'D1': 3, 'D2': 1, 'D3': 2, '3D6': 13}, {'Roll #': 11, 'D1': 6, 'D2': 2, 'D3': 5, '3D6': 13}, {'Roll #': 12, 'D1': 2, 'D2': 4, 'D3': 1, '3D6': 13}, {'Roll #': 13, 'D1': 5, 'D2': 5, 'D3': 6, '3D6': 13}, {'Roll #': 14, 'D1': 1, 'D2': 5, 'D3': 4, '3D6': 13}, {'Roll #': 15, 'D1': 6, 'D2': 6, 'D3': 6, '3D6': 13}, {'Roll #': 16, 'D1': 4, 'D2': 3, 'D3': 1, '3D6': 13}, {'Roll #': 17, 'D1': 2, 'D2': 2, 'D3': 2, '3D6': 13}, {'Roll #': 18, 'D1': 4, 'D2': 2, 'D3': 3, '3D6': 13}, {'Roll #': 19, 'D1': 2, 'D2': 1, 'D3': 3, '3D6': 13}, {'Roll #': 20, 'D1': 5, 'D2': 4, 'D3': 5, '3D6': 13}, {'Roll #': 21, 'D1': 5, 'D2': 2, 'D3': 5, '3D6': 13}, {'Roll #': 22, 'D1': 5, 'D2': 5, 'D3': 3, '3D6': 13}, {'Roll #': 23, 'D1': 3, 'D2': 1, 'D3': 5, '3D6': 13}, {'Roll #': 24, 'D1': 6, 'D2': 1, 'D3': 3, '3D6': 13}, {'Roll #': 25, 'D1': 1, 'D2': 6, 'D3': 2, '3D6': 13}, {'Roll #': 26, 'D1': 5, 'D2': 3, 'D3': 4, '3D6': 13}, {'Roll #': 27, 'D1': 5, 'D2': 4, 'D3': 4, '3D6': 13}, {'Roll #': 28, 'D1': 2, 'D2': 5, 'D3': 2, '3D6': 13}, {'Roll #': 29, 'D1': 6, 'D2': 4, 'D3': 2, '3D6': 13}, {'Roll #': 30, 'D1': 5, 'D2': 3, 'D3': 5, '3D6': 13}, {'Roll #': 31, 'D1': 5, 'D2': 3, 'D3': 3, '3D6': 13}, {'Roll #': 32, 'D1': 6, 'D2': 3, 'D3': 6, '3D6': 13}, {'Roll #': 33, 'D1': 3, 'D2': 6, 'D3': 6, '3D6': 13}, {'Roll #': 34, 'D1': 5, 'D2': 5, 'D3': 3, '3D6': 13}, {'Roll #': 35, 'D1': 3, 'D2': 4, 'D3': 2, '3D6': 13}, {'Roll #': 36, 'D1': 6, 'D2': 2, 'D3': 2, '3D6': 13}, {'Roll #': 37, 'D1': 1, 'D2': 4, 'D3': 6, '3D6': 13}, {'Roll #': 38, 'D1': 5, 'D2': 2, 'D3': 6, '3D6': 13}, {'Roll #': 39, 'D1': 3, 'D2': 5, 'D3': 3, '3D6': 13}, {'Roll #': 40, 'D1': 6, 'D2': 4, 'D3': 5, '3D6': 13}, {'Roll #': 41, 'D1': 4, 'D2': 1, 'D3': 4, '3D6': 13}, {'Roll #': 42, 'D1': 6, 'D2': 1, 'D3': 5, '3D6': 13}, {'Roll #': 43, 'D1': 4, 'D2': 4, 'D3': 5, '3D6': 13}, {'Roll #': 44, 'D1': 5, 'D2': 2, 'D3': 3, '3D6': 13}, {'Roll #': 45, 'D1': 4, 'D2': 5, 'D3': 5, '3D6': 13}, {'Roll #': 46, 'D1': 2, 'D2': 5, 'D3': 3, '3D6': 13}, {'Roll #': 47, 'D1': 2, 'D2': 5, 'D3': 3, '3D6': 13}, {'Roll #': 48, 'D1': 6, 'D2': 3, 'D3': 4, '3D6': 13}, {'Roll #': 49, 'D1': 6, 'D2': 2, 'D3': 1, '3D6': 13}, {'Roll #': 50, 'D1': 3, 'D2': 3, 'D3': 3, '3D6': 13}, {'Roll #': 51, 'D1': 5, 'D2': 3, 'D3': 5, '3D6': 13}, {'Roll #': 52, 'D1': 2, 'D2': 4, 'D3': 5, '3D6': 13}, {'Roll #': 53, 'D1': 6, 'D2': 3, 'D3': 5, '3D6': 13}, {'Roll #': 54, 'D1': 5, 'D2': 5, 'D3': 4, '3D6': 13}, {'Roll #': 55, 'D1': 6, 'D2': 6, 'D3': 1, '3D6': 13}, {'Roll #': 56, 'D1': 4, 'D2': 4, 'D3': 6, '3D6': 13}, {'Roll #': 57, 'D1': 5, 'D2': 3, 'D3': 1, '3D6': 13}, {'Roll #': 58, 'D1': 1, 'D2': 6, 'D3': 2, '3D6': 13}, {'Roll #': 59, 'D1': 1, 'D2': 2, 'D3': 2, '3D6': 13}, {'Roll #': 60, 'D1': 2, 'D2': 1, 'D3': 5, '3D6': 13}, {'Roll #': 61, 'D1': 6, 'D2': 6, 'D3': 2, '3D6': 13}, {'Roll #': 62, 'D1': 5, 'D2': 2, 'D3': 4, '3D6': 13}, {'Roll #': 63, 'D1': 5, 'D2': 4, 'D3': 5, '3D6': 13}, {'Roll #': 64, 'D1': 6, 'D2': 4, 'D3': 4, '3D6': 13}, {'Roll #': 65, 'D1': 3, 'D2': 5, 'D3': 4, '3D6': 13}, {'Roll #': 66, 'D1': 4, 'D2': 6, 'D3': 1, '3D6': 13}, {'Roll #': 67, 'D1': 6, 'D2': 2, 'D3': 2, '3D6': 13}, {'Roll #': 68, 'D1': 2, 'D2': 2, 'D3': 5, '3D6': 13}, {'Roll #': 69, 'D1': 6, 'D2': 6, 'D3': 2, '3D6': 13}, {'Roll #': 70, 'D1': 1, 'D2': 6, 'D3': 6, '3D6': 13}, {'Roll #': 71, 'D1': 1, 'D2': 2, 'D3': 4, '3D6': 13}, {'Roll #': 72, 'D1': 6, 'D2': 2, 'D3': 1, '3D6': 13}, {'Roll #': 73, 'D1': 4, 'D2': 1, 'D3': 5, '3D6': 13}, {'Roll #': 74, 'D1': 4, 'D2': 3, 'D3': 2, '3D6': 13}, {'Roll #': 75, 'D1': 4, 'D2': 2, 'D3': 6, '3D6': 13}, {'Roll #': 76, 'D1': 5, 'D2': 1, 'D3': 4, '3D6': 13}, {'Roll #': 77, 'D1': 2, 'D2': 3, 'D3': 3, '3D6': 13}, {'Roll #': 78, 'D1': 6, 'D2': 6, 'D3': 1, '3D6': 13}, {'Roll #': 79, 'D1': 6, 'D2': 1, 'D3': 6, '3D6': 13}, {'Roll #': 80, 'D1': 5, 'D2': 3, 'D3': 1, '3D6': 13}, {'Roll #': 81, 'D1': 2, 'D2': 6, 'D3': 3, '3D6': 13}, {'Roll #': 82, 'D1': 6, 'D2': 5, 'D3': 5, '3D6': 13}, {'Roll #': 83, 'D1': 1, 'D2': 6, 'D3': 5, '3D6': 13}, {'Roll #': 84, 'D1': 2, 'D2': 5, 'D3': 1, '3D6': 13}, {'Roll #': 85, 'D1': 5, 'D2': 1, 'D3': 5, '3D6': 13}, {'Roll #': 86, 'D1': 3, 'D2': 2, 'D3': 1, '3D6': 13}, {'Roll #': 87, 'D1': 1, 'D2': 3, 'D3': 6, '3D6': 13}, {'Roll #': 88, 'D1': 4, 'D2': 2, 'D3': 1, '3D6': 13}, {'Roll #': 89, 'D1': 4, 'D2': 6, 'D3': 6, '3D6': 13}, {'Roll #': 90, 'D1': 1, 'D2': 4, 'D3': 1, '3D6': 13}, {'Roll #': 91, 'D1': 3, 'D2': 5, 'D3': 4, '3D6': 13}, {'Roll #': 92, 'D1': 2, 'D2': 4, 'D3': 3, '3D6': 13}, {'Roll #': 93, 'D1': 6, 'D2': 4, 'D3': 1, '3D6': 13}, {'Roll #': 94, 'D1': 5, 'D2': 5, 'D3': 4, '3D6': 13}, {'Roll #': 95, 'D1': 4, 'D2': 4, 'D3': 5, '3D6': 13}, {'Roll #': 96, 'D1': 1, 'D2': 3, 'D3': 4, '3D6': 13}, {'Roll #': 97, 'D1': 3, 'D2': 3, 'D3': 2, '3D6': 13}, {'Roll #': 98, 'D1': 5, 'D2': 3, 'D3': 3, '3D6': 13}, {'Roll #': 99, 'D1': 4, 'D2': 3, 'D3': 4, '3D6': 13}, {'Roll #': 100, 'D1': 6, 'D2': 2, 'D3': 5, '3D6': 13}]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# Write your solution here\n",
    "import csv\n",
    "with open('random-dice.csv','w') as rd:\n",
    "    x = {}\n",
    "    lst = []\n",
    "    for i in range(1,101):\n",
    "        x['Roll #'] = i\n",
    "        x['D1'] = random.randint(1,6)\n",
    "        x['D2'] = random.randint(1,6)\n",
    "        x['D3'] = random.randint(1,6)\n",
    "        x['3D6'] = r1+r2+r3\n",
    "        lst.append(x.copy())\n",
    "    print(lst)\n",
    "    head_6 = ['Roll #','D1','D2','D3','3D6']\n",
    "    writer = csv.DictWriter(rd,fieldnames=head_6)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(lst)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 07 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(5 Points)\n",
    "\n",
    "Various characters are used to delimit CSV-style files such as colons, semicolons and tabs in addition to commas. Open the file `semi-delimited.csv` delimited with semicolons (\";\") and rewrite the file to `tab-delimited.csv` setting the delimiter to the tab character. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your solution here\n",
    "with open('semi-delimited.csv','rU') as scsv:\n",
    "    reader = csv.reader(scsv,delimiter=';')\n",
    "    with open('tab-delimited.csv','w') as tcsv:\n",
    "        writer = csv.writer(tcsv,delimiter='\\t')\n",
    "        writer.writerows(reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 08 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(5 Points)\n",
    "\n",
    "Another approach to dealing with CSV files in Python is to use `DictReader` to form an *ordered dictionary* with keys based on the header. Use DictReader to open the file `username.csv` and assign the first row of data as a dictionary to the variable `dict_row_first` and the last row of data to the variable `dict_row_last`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your solution here\n",
    "with open('username.csv','r') as df:\n",
    "    reader = csv.DictReader(df)\n",
    "    dict_row_first = next(reader)\n",
    "    \n",
    "    for i in reader:\n",
    "        pass\n",
    "        dict_row_last = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 09 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(10 Points)\n",
    "\n",
    "Provided with three dictionaries for employee data (below), write a CSV file `employee.csv` that captures the three employee records and include a header row at the beginning of the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "employee_data_1 = {\n",
    "\"Name\": \"Graham Chapman\",\n",
    "\"Hire Date\": \"03/15/14\",\n",
    "\"Salary\": 50000,\n",
    "\"Sick Days\": 10}\n",
    "\n",
    "employee_data_2 = {\n",
    "\"Name\": \"John Cleese\",\n",
    "\"Hire Date\": \"06/01/14\",\n",
    "\"Salary\": 55000,\n",
    "\"Sick Days\": 11}\n",
    "\n",
    "employee_data_3 = {\n",
    "\"Name\": \"Eric Idle\",\n",
    "\"Hire Date\": \"not employed\",\n",
    "\"Salary\": 0,\n",
    "\"Sick Days\": 0}\n",
    "\n",
    "\n",
    "new_dict = [employee_data_1,employee_data_2,employee_data_3]\n",
    "header_9 = [\"Name\",\"Hire Date\",\"Salary\",\"Sick Days\"]\n",
    "\n",
    "\n",
    "with open('employee.csv', 'w') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=header_9)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(new_dict)\n",
    "\n",
    "# Write your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 10 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(5 Points)\n",
    "\n",
    "Given the dictionary `DATASET` below, write this to a JSON formatted file called `nap.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET = [\n",
    "    {'name': \"John\", 'age': 52, 'postcode': 5002},  \n",
    "    {'name':\"Ye\", 'age': 18, 'postcode': 3005},  \n",
    "    {'name':\"Siobhan\", 'age': 34, 'postcode': 2356}\n",
    "]\n",
    "\n",
    "# Write your solution here\n",
    "with open('nap.json','w') as file:\n",
    "    json.dump(DATASET,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 11 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(5 Points)\n",
    "\n",
    "The `MENU_DEF` dictionary represents multi-lingual labels for a menu in a file system application. Save this data to a JSON file `menu.json` in `utf-16` encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MENU_DEF = {'menu': {'id': 'file',\n",
    "          'popups': [{'language': 'English',\n",
    "                      'menuitem': [{'onclick': 'CreateNewDoc()',\n",
    "                                    'value': 'New'},\n",
    "                                   {'onclick': 'OpenDoc()', 'value': 'Open'},\n",
    "                                   {'onclick': 'CloseDoc()',\n",
    "                                    'value': 'Close'}]},\n",
    "                     {'language': 'Deutsch',\n",
    "                      'menuitem': [{'onclick': 'CreateNewDoc()',\n",
    "                                    'value': 'Neu'},\n",
    "                                   {'onclick': 'OpenDoc()', 'value': 'Offen'},\n",
    "                                   {'onclick': 'CloseDoc()',\n",
    "                                    'value': 'Schließen'}]}]}}\n",
    "\n",
    "# Write your solution here\n",
    "with open('menu.json','w',encoding='utf-16') as file:\n",
    "    json.dump(MENU_DEF,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 12 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(10 Points)\n",
    "\n",
    "You are provided with the JSON file `glossary.json`. Deserialise the file and navigate the created representation of the JSON file to find the value of the name:value pair with key `\"GlossSeeAlso\"`. Assign this list to the Python variable `see_also_list`.\n",
    "\n",
    "For example, to find the value for the key `\"GlossDiv\"` it would be necessary to open the file, deserialise it to a Python object (say `glossary`) and then navigate the mix of dictionaries and lists to find:\n",
    "\n",
    "```python\n",
    "    # deserialise to 'glossary'\n",
    "    div = glossary['glossary']['GlossDiv']\n",
    "    print (div)\n",
    "    ...\n",
    "    {'GlossList': {'GlossEntry': {'Abbrev': 'ISO 8879:1986',\n",
    "                              'Acronym': 'SGML',\n",
    "                               ...   \n",
    "```      \n",
    "\n",
    "In this case we are accessing the nested dictionaries using `glossary['glossary']['GlossDiv']`.\n",
    "\n",
    "---\n",
    "<details>\n",
    "  <summary><span style=\"color:blue\">Navigating a JSON representation</span></summary>\n",
    "    After deserialisation, we know that Python's representation of a JSON file is a mix of dictionaries and lists. Once you deserialise a file, it is often helpful to print or pretty print (from the library <code>pprint</code>) the variable and compare the name:value pairs with the original file. Alternately, open the JSON file in Jupyter Notebook - this does a great job of allowing traversal of nested dictionaries that are the hallmark of complex JSON representations.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 13 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(10 Points)\n",
    "\n",
    "Let's append 'JSON' to the \"See also\" entry of the glossary item on SGML. In the list identified by the key/name `GlossSeeAlso`, append `'JSON'` to the list of `['GML', 'XML']` and write the amended glossary to the file `json-glossary.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 14 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(5 Points)\n",
    "\n",
    "Given the string of JSON data in the cell below, convert this into a Python representation and add a new person's details as:\n",
    "  - **name**: Menasha, \n",
    "  - **age**: 21 and \n",
    "  - **postcode**: 5000.  \n",
    " \n",
    "You should now have a Python list with four elements all having identical dictionary keys. Serialise your list to a new file `json-string.json`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "JSON_STRING = '''[ {\"name\": \"Ali\",   \"age\": 52, \"postcode\": 5002},\n",
    "                   {\"name\": \"Ye\",    \"age\": 18, \"postcode\": 3005},\n",
    "                   {\"name\": \"Matty\", \"age\": 97, \"postcode\": 6061}\n",
    "              ]'''\n",
    "import json\n",
    "# Write your solution here\n",
    "jdata = json.loads(JSON_STRING)\n",
    "new_data = {'name':'Mensasha', 'age':21, 'postcode':5000}\n",
    "jdata.append(new_data)\n",
    "with open('json-string.json','w') as file:\n",
    "    json.dump(jdata,file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 15 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(5 Points)\n",
    "\n",
    "Write a Python program to create a JSON file `encode-decode.json` that stores a list of the following Python values:\n",
    "\n",
    "- None\n",
    "- True\n",
    "- False\n",
    "- an empty list\n",
    "- an empty string\n",
    "- an empty dict\n",
    "- integer 0\n",
    "- float 1.0\n",
    "\n",
    "Open the file in a text editor and observe the transcoding between Python values and their representation in JSON - in particular the handling of essentially empty objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 16 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(10 Points)\n",
    "\n",
    "We can get a string of JSON text from a website or API using the `request` library. The function call to invoke a request is as follows:\n",
    "```python\n",
    "import requests\n",
    "web_request = requests.get(<some url>)\n",
    "json_string = response.text\n",
    "```\n",
    "We can then convert the JSON string into a Python object using `json.loads()` as we already know.\n",
    "\n",
    "Write a program that makes a web request to the URL:  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;   https://jsonplaceholder.typicode.com/todos <br />\n",
    "for a JSON string. Observe that this is a list of \"todo list\" items. \n",
    "\n",
    "Once you have this list of items (Python dictionaries), set the 'completed' status for each todo list item and save to the file `todo-list.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your solution here\n",
    "import json\n",
    "import requests\n",
    "url = \"https://jsonplaceholder.typicode.com/todos\"\n",
    "web_request = requests.get(url)\n",
    "json_txt = web_request.text\n",
    "data = json.loads(json_txt)\n",
    "new = []\n",
    "\n",
    "for i in data:\n",
    "    i['completed'] = False\n",
    "    new.append(i)\n",
    "with open('todo-list.json','w') as file:\n",
    "    json.dump(new,file)\n",
    "#for i in data:\n",
    "#    for x in i.keys():\n",
    "       #if i['completed'] != 'False':\n",
    "#        i.update({'completed':False})\n",
    "#        json.dump(i,open('todo-list.json','a'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "otter": {
   "tests": {
    "Question 01": {
     "name": "Question 01",
     "points": 5,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "Question 02": {
     "name": "Question 02",
     "points": 5,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "Question 03": {
     "name": "Question 03",
     "points": 5,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "Question 04": {
     "name": "Question 04",
     "points": 5,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "Question 05": {
     "name": "Question 05",
     "points": 5,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "Question 06": {
     "name": "Question 06",
     "points": 5,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "Question 07": {
     "name": "Question 07",
     "points": 5,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "Question 08": {
     "name": "Question 08",
     "points": 5,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "Question 09": {
     "name": "Question 09",
     "points": 10,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "Question 10": {
     "name": "Question 10",
     "points": 5,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "Question 11": {
     "name": "Question 11",
     "points": 5,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "Question 12": {
     "name": "Question 12",
     "points": 10,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "Question 13": {
     "name": "Question 13",
     "points": 10,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "Question 14": {
     "name": "Question 14",
     "points": 5,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "Question 15": {
     "name": "Question 15",
     "points": 5,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "Question 16": {
     "name": "Question 16",
     "points": 10,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
